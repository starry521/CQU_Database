# 数据库系统

有关数据库的三大会议：ICDB、VLDB、SIGMOD

[TOC]



## CH1/2 引言

---

### DBMS模型分为：概念模型、数据模型

> 数据库逻辑设计后得到->概念模型
>
> 关系型数据库用什么表示->表格

### **数据库属于基础软件平台**

### 一些常见的模型

> 键值模型：Redis、HBase
>
> 文档模型：MongoDB

### 数据库系统&数据库的**开发运行环节**：

1. 需求分析

   > 功能需求+数据需求

2. 系统设计

   > 系统功能设计
   >
   > > 数据结构设计：**概念设计**+**逻辑设计**
   > >
   > > 数据存储设计：**物理设计**

3. 系统实现

4. 系统运行与维护

### 数据库视图技术

> 三级结构、两级映射
>
> 数据->逻辑->物理

### *几个问题（面试）

> 1. 数据库数据存储在磁盘的什么位置上？
> 2. 如果要迁移一个数据库，需要迁移哪些文件？

## CH3 数据库需求分析

---

> 主要内容：数据流程图、数据字典、UML类图

#### 两大基本任务

> 1. **应用需求**：有哪些应用
> 2. **数据需求**：涉及哪些数据

#### 基本方法

> 数据流程图、UML类图、时序图等

#### 需求结果的分析

> 最终结果是：一套形式化的规范文档

#### 其他任务

> 数据约束、使用频率、性能需求、使用环境、界面友好性、安全要求

## CH4/5 概念设计--“E-R模型”（实体-联系模型）	*必考*

---

### 三个基本要素

> 1、2：**实体集**&**属性**（矩形）
>
> > 属性若是**主键**（用于区分实体的属性/唯一标识符），则需要标记**下划线**
> >
> > 属性间不需要用横线隔开
> >
> > 实体集采用**双线矩形**表示**弱实体集**，其没有键，存在依赖于主实体集，通过主实体集的键和自身的辨识符予以分辨（题目未特地申明时无需考虑）
>
> 3：**联系集**（菱形&连线）	
>
> > 对于一对一、一对多、多对一、多对多等情况，**箭头标在“一”方**，否则不标记箭头
> >
> > 联系集上也可有**属性**，用**虚线**连接
> >
> > 若实体集成员**全部参与**，则使用**双线线段**进行标记（题目未明确要求时，一般可忽略）
> >
> > 实体集**自身也可有联系**
> >
> > 联系集采用**双线菱形**表示**弱实体集**，其没有键，存在依赖于主实体集，通过主实体集的键和自身的辨识符予以分辨（题目未特地申明时无需考虑）

### 复合属性与多元属性集

> 1. 复合属性：包含复合属性、双重复合属性、多值属性、导出属性
> 2. 多元联系集与角色（roles）：可进行二元分解 

### E-R模型设计注意问题

> 1. 实体和实体集的选择
>
> 2. 指针实现有限表示无限
>
> 3. 属性放置的位置
>
>    > 多值属性和复合属性：多值属性和复合属性可以相互替代转换
>
> 4. 使用实体集还是联系集

### 扩展E-R模型

>  1. 特化与概化（特殊化与一般化）
>
>     > 不相交特化与重叠特化
>     >
>     > 部分概化与全部概化
>     >
>  2. 聚集

## CH6 逻辑设计--“关系模型”

---

### 数据模型

#### 	**三大基本要素**：	*易考*

> 1. **数据结构**：由一组创建数据库的规则（定义数据库的结构）组成
>
> 2. **数据操作**：定义对数据进行的操作类型（增删改查）
>
> 3. **约束条件**（完整性约束）：一组数据完整性定义规则，确保数据正确性

#### 	层次（数据）模型

> 描述非层次化数据时，采用**创建副本**（存在数据冗余以及数据一致性问题）、**虚拟记录**（优化方法，采用类指针方法进行映射，但效率较低）

#### 	网状（数据）模型

> 能够更直接的描述现实世界的关系、且效率较高，但是DDL（数据定义语言）较为复杂

### 关系模型

> 实际应用场景中无需完全满足三大范式，具体问题具体分析

> 第1范式（1NF）
>
> > 要求关系的属性具有原子性(属性不可多值)
> >
> > 可使用纵向展开（添加记录，不固定）、横向展开（添加属性，固定）

### 三大约束

> 1. **实体完整性约束**：主键的值不能重复，也不能为空。
> 2. **参照完整性约束**：表示的是两个关系之间的联系，是表与表之间的引用。不允许在一个关系中引用另一个关系中不存在的对象。对应的就是外键，外键约束实现参照完整性，表与表之间要保证同步。
> 3. **域完整性约束（用户自定义约束）**：用户根据实际情况，对表中属性值的取值范围做出的规定。如性别只能为男/女等。	对应SQL语句中 ‘check’指令。

#### 候选码、主码、超码、外键：

> 候选码：具有唯一辨识性的最小属性集合，可以为空
>
> 主码（键）：具有唯一辨识性的某一属性，不可为空；故而主码一定是候选码
>
> 超码：能够区分两条记录的属性组合；故而只要含有一个候选码就必然是超码
>
> 外键：表与表之间共有的索引键，不建议使用

### 关系运算

> 选择、投影、并、差、笛卡尔积、更名（重命名）

## CH7 关系模型的其他知识

---

### 基本关系代数

> 选择σ、投影Π（自带去重）、并集∪、差集—、笛卡尔积×、重命名ρ

### 扩展关系代数

> 自然连接⋈（有相同属性自动连接）、左外连接⋊（左侧全保留，右侧若无对应则填充null）、右外连接⋉、全外连接
>
> 聚合函数运算

### E-R图转换为关系模式的**规则**【重点】

> 1. **为每个实体集创建表**
> 2. **多对多**时为联系集创建表：该联系集表以**两方主键的组合**为主键
> 3. 其余的无需创建表：一对多时直接将联系存储在多方的表中，一对一时直接存储在任意一方的表中即可。
> 4. 注意**外键**标注

## CH8 基本SQL【重点】

---

$$
SQL\begin{cases}
DML&数据操纵语言\\
DDL&数据定义语言\\
DQL&数据查询语言
\end{cases}
$$

SELECT	字段1,... 	AS	重命名	FROM	表	

[WHERE	条件	[GROUP	BY	（聚类）字段	HAVING	限制条件	[ORDER	BY	...	LIMIT	...	]]]

> ps: 聚类筛选时必须用**''having''**而非**''where''**

## CH9 高级SQL

---

### 视图

> create view 视图名 as 表
>
> 视图是虚拟的，并不额外占用空间

### 完整性约束

> 外键约束方式、断言

### 授权

> grant用于授予权限、revoke用于收回权限
>
> grant时：with grant option允许转授权限
>
> revoke时：cascade级联回收权限；restrict不进行级联回收
>
> 授权图

### SQL函数与过程

> 用户自定义函数（user defined function,udf）
>
> ![image-20230320145050268](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202303201450530.png)
>
> 区别：函数有返回值，过程没有（用 out标注可能会发生变化的变量）

### 用户定义类（UDT）与域

> 区别：
>
> - type无法添加用户限制
>
> - 域不是强制类型，一个域可以被赋予另一个域类型

### 触发器

> 触发可用于复制/备份数据库



## CH10 11 12 关系模式设计优化【重点】

### 冗余

>  冗余的存在是因为存在约束，尤其是函数依赖
>
> 优化方式：模式分解

### 函数依赖（FDs	functional dependency）【重点】

> A->B	当且仅当A的值相同时，对应B的值唯一确定
>
> ## 函数依赖理论
>
> Armstrong公理：	" RAT "
>
> > - Reflesivity（自反律）
> >
> > - Augmentation（增广律）
> >
> > - Transitivity（传递律）
> >
> >   ![image-20230322104550839](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202303221045700.png)
>
> 由上可推导出：
>
> > - 合并律
> >
> >    X->Y & X->Z  ==> X->YZ
> >
> > - 分解律
> >
> >    X->YZ  ==> X->Y , X->Z
> >
> > - 伪传递律
> >
> >    X->Y & WY->Z  ==> WX->Z
> >    
> >    ![image-20230322104640340](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202303221046211.png)



### 第一范式	1NF

> - 每个属性必须是==原子属性==

### 第二范式	2NF

> - 满足第一范式
> - 所有非主属性必须==完全依赖==于整个候选码，而不能依赖于候选码的部分属性

### 第三范式	3NF

>- 满足第二范式
>- 非主属性==直接依赖==于候选键，不存在==传递依赖==（非主属性之间的依赖）
>
>判断标准：左边是超键  / 右边是候选码的一部分

### 3NF分解【必考】

> > 3NF分解满足无损分解和保持依赖，即==**双保持**==
>
> 3NF满足：
>
> - 非平凡关系，左为超键
> - 或非平凡关系，==右为候选键的一部分==
> - 或平凡关系
>
> # 正则覆盖（最小函数依赖集）Fc
>
> 去除无关属性：即去除该属性后不影响函数依赖集的闭包（如WX->WY 中的W）
>
> 两步：
>
> - 满足结合律的进行结合
> - 尝试删除某个属性，判断是否无影响
>
> > CSDN：
> >
> > 若要判断的属性位于依赖的**右侧**，例如{AB→C，……}，则删除该属性，在余下的函数依赖集F'中计算该依赖左部集合的闭包α+。若α+中包含要判断的属性，则该属性就是无关属性（冗余）
> >
> >  例2：F{A→BC，B→AC，C→AB}
> >
> >           关注B属性。它在依赖右侧。删除该属性，余下F'={A→C，B→AC，C→AB},计算左侧剩余属性集（A）的闭包（A）+。
> >                                                                                                                             
> >           因为A→C，C→AB，所以（A）+中包含删去的属性B
> >                                                                                                                             
> >           故B是无关属性
> >
> > 若要判断的属性位于依赖的**左侧**，例如{AB→C}，则删除该属性，在原本的依赖集F中计算该依赖左部集合的闭包α+。若α+闭包中包含该依赖右侧所有的属性，则该属性则是无关属性
> >
> > **PS：若类似于A->B，则不做操作**
>
> # 分解步骤
>
> > ps: 可以先用BCNF分解尝试，看是否保持依赖
>
> 1. 求正则覆盖
>
> 2. 为每个依赖形成子模式，若有被包含的则删去
>
> 3. 判断候选键模式是否已经被2中的模式包含，若不包含则添加
>
>    ![image-20230329110123649](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202303291101455.png)

### Boyce-Codd范式	BCNF

> - 满足第三范式
> - 平凡关系：当且仅当 X⊆Y , Y->X
> - 非平凡关系中，左值为超键（码）

### BCNF范式分解

> 如果F中的函数依赖X->A违背BCNF，那么分解R为 R-A和 XA 
>
> ps：无损，但**并不能保证是保持依赖分解**

### 3NF与BCNF分解的选择

> ![image-20230329113357233](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202303291133065.png)

### 函数依赖集的闭包F+

> 对原有规则使用三大定律得到的所有规则和其本身组成的集合
>
> 指数级

### 属性集的闭包（闭包：closure）

> 属性集X的闭包	就是由X在函数依赖集F上蕴含的所有属性的集合
>
> 线性级
>
> ![image-20230322110248330](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202303221102986.png)

### 无损分解

> 共有属性为超码，能够确定其中一个分解的全集即为无损
>
> 即自然连接后可还原

### 保持函数依赖

>在F中存在的规则投影到F'中依然存在

### 候选键的确定

> - 所有在规则中只位于左侧的是候选键
> - 所有在规则中只位于右侧的不是候选键
> - 所有未在规则中出现的是候选键
> - 在两侧都出现的单独判断





## CH13 14 物理设计

### 物理设计的主要工作

> - 确定定长/变长记录
> - 影响数据存放数据的搜索码
> - 确定是否还需要建立辅助索引
> - 确定是否采用多表聚集文件存储
> - 确定划分为多少个数据库
> - 确定文件存放的物理路径(如存储介质等)

### 数据库缓冲区

> 替换原则 （如LRU最近最少使用【底层可使用堆实现】，FIFO等）

### 元数据

> 数据的数据（信息），如表名等信息

### 索引【重点】

> $$
> \begin{cases}
> 顺序索引 ：基于值的顺序排序 \\
> 散列索引：基于将值存储到若干散列桶中（哈希）
> \end{cases}
> $$
>
> $$
> \begin{cases}
> 稠密索引\\
> 稀疏索引
> \end{cases}
> $$
>
> 多级索引
>
> 辅助索引
>
> **B+树【不考】
>
> **散列索引【不考】

## CH15 16 查询优化【关系代数】

### SQL执行过程

> $$
> SQL -> 解析 -[AST]-> 优化 -[逻辑/物理]-> 执行 \\\\
> 
> 解析
> \begin{cases}
> 词法解析 \\
> 语法解析 \\
> 语义解析
> \end{cases} \\\\
> 
> 优化
> \begin{cases}
> Rule-Based\ Optimizer \\
> Cost-Based\ Optimizer \\
> Learn-Based\ Optimizer
> \end{cases}
> $$
>

### 查询代价

> $$
> 查询代价
> \begin{cases}
> 集中式数据库 && 磁盘IO >> 执行耗时 \\
> 分布式存储 && 执行耗时+磁盘IO+传输延迟
> \end{cases}
> $$
>

### 选择操作的实现

> SELECT <属性 > FROM <table> WHERE <条件表达式>
>
>  $$
>  条件表达式
>  \begin{cases}
>  无条件&&遍历\\
>  点查询&&哈希索引\\
>  范围查询&&B+树\\
>  组合查询&&先利用一个索引，在校验是否符合第二个&&或&&两次索引求交集
>  \end{cases}
>  $$
>
> 

### 优化TIPS	【课本P331】

> > 可参考：[【数据库下】 第四章 查询处理（查询优化）_51CTO博客_数据库查询优化](https://blog.51cto.com/u_15127516/4114677)
>
> 先选择后连接、只投影需要的属性
>
> 选择下推、投影下推
>
> 笛卡尔积、自然连接 均不适用交换律（顺序会发生变化）
>
> 连接优先做小的
>
> 相关子查询用join替代【否则只能双循环】
>
> 外连接消除
>
> DISTINCT消除
>
> IN 谓词展开	改写成等值的过滤条件以利用索引
>
> 视图展开

## CH17 18 19 事务管理

### 事务的概念

> 构成单一**逻辑工作单元**的操作集合
>
> 事务是指一组数据库操作，要么全部成功，要么全部失败。这对于需要数据完整性和一致性的应用程序非常重要。

### 事务的特性【四大特性--ACID'酸'】

>1. Atomicity原子性
>
>   >  不可再分
>
>2. Consistency一致性
>
>   >  不改变操作数之和 
>
>3. isolation隔离性
>
>   >  事务支持并发执行，互不干扰
>
>4. durability持久性
>
>   >  事务完成后对数据库的影响是永久的
>
>## VS. 分布式存储的特性 CAP
>
>C 一致性、 A 可用性、 P 容错性

### 事务的状态【五大状态】应该不考

> ## 活动状态
>
> 事务在执行时的状态叫活动状态。
>
> ## 部分提交状态
>
> 事务中最后一条语句被执行后的状态叫部分提交状态。
>
> ## 失败状态
>
> 事务不能正常执行的状态叫失败状态。
>
> ## 提交状态
>
> 事务在部分提交后，将往硬盘上写入数据，当最后一条信息写入后的状态叫提交状态。进入提交状态的事务就成功完成了。
>
> ## 中止状态
>
> 事务回滚并且数据库已经恢复到事务开始执行前的状态叫中止状态。

### 可串行化调度

> ### 调度
>
> ### 冲突可串行化
>
> ### 调度优先图
>
> 有冲突
>
> ### 冲突可串行化的判断方法
>
> 如果调度优先图中有环，则是**非冲突可串行化的**
>
> 

### 事务的隔离级别

> - 可串行化（序列化）
>
> - 可重复读
>
>   幻读（只读）
>
> - 已提交读（读已提交）
>
>   出现不可重复读的情况，第一次读取后数据被改变，第二次再读与第一次不一致
>
> - 未提交读（读未提交）
>
>   读到的数据会被尚未提交的事务影响，即**脏读**
>
> ![image-20230424155054986](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202304241550736.png)

### 事务的分类

> - 显示事务
>
>   手动begin与commit
>
> - 隐性事务
>
>   在上一个事务提交或回滚后自动启动新事务
>
> - 自动提交事务
>
>   如单条语句

### 并发控制技术↓

$$
并发控制技术
\begin{cases}
锁\\
两阶段封锁协议
\end{cases}
$$



### 锁

> - 共享锁【Lock-S】
>
>   ​	获取后**只读不写**
>
> - 排他锁【Lock-X】
>
>   ​	获取后**可读可写**

### 两阶段封锁协议

> ## 死锁与活锁
>
> ---
>
> 死锁
>
> **活锁（饥饿）**：出现一个事务永远（长时间）等待某一数据项被其他事务释放后才能进行封锁的现象
>
> ## 两阶段
>
> ---
>
> $$
> 两阶段
> \begin{cases}
> 增长阶段&&事务可获得锁，但不能释放锁\\
> 缩减阶段&&事务可释放锁，但不能获得锁
> \end{cases}
> \\ps:简言之，不能交叉获得锁与释放锁
> \\封锁点：最后一次加锁的位置
> $$
>
> 
>
> ## 两阶段封锁协议的作用
>
> ---
>
> 两阶段封锁协议**能够保证冲突可串行化**，但不能解决死锁问题
>
> ps: 冲突可串行化**未必满足**两阶段封锁协议
>
> ## 级联 &严格两阶段封锁协议
>
> ---
>
> 级联会导致一个事务回滚时，多个与之有交叉的事务也需要回滚
>
> **严格两阶段封锁协议**：除了要求封锁是两阶段的之外，还要求事务持有的所有**排他锁必须在事务提交之后再释放**。【事务提交之前不能释放排他锁】
>
> V.S.
>
> **强两阶段封锁协议**: 事务提交前不得释放任何锁
>
> ## 锁转换
>
> ---
>
> 锁的升级与降级

### 基于图的协议*

> ## 偏序
>
> ---
>
> 遵从**偏序**：若di->dj，则任何访问di,dj的事务，必须保证di先于dj被访问
>
> ## 树形协议
>
> ---
>
> 规则：
>
> - 首次加锁可对任何数据项进行【将工作区设为以它作为根节点的子树】
>
> - 之后加锁时要保证拥有所有父节点的锁
>
> - 加锁并释放后，不得再次加锁
>
> 优点：
>
> - 树形协议可**保证冲突可串行化**；
> - 可**保证不会产生死锁**；
> - 树形协议可较早的释放锁，减少事务的等待时间，从而增强调度的并发性。
>
> 缺点：
>
> - 树形协议**不能保证可恢复性**；
> - 树形协议**不能保证无级联回滚**；【但是若添加“在事务结束之前不允许释放任何X锁“，牺牲一定的并发度，则可以保证可恢复性与无级联回滚】；
>
> - 树形协议可能会对不需要的数据加锁，从而增加乐锁的开销与额外的等待时间，降低并发性。【加锁需要保证父节点有锁】
>
> ps: 可恢复性：若已提交事务没有读过被撤销事务的写数据，则具有可恢复性

### 死锁

> ## 死锁的判定
>
> ---
>
> 等待图中出现环路，相互等待
>
> ## 死锁的解除方法
>
> ---
>
> 1. 牺牲一个事务【最小代价等】
> 2. 在事务开始前封锁它需要的所有数据
> 3. 要求所有事务按一定顺序封锁数据
> 4. 基于抢占与事务回滚：
>    - wait-die比占有的事务老则等待，新则回滚；
>    - wound-wait比占有的事务新则等待，老则回滚；

### 多粒度封锁协议

> ## 多粒度锁
>
> ---
>
> 行级锁、表级锁、库级锁、用户级锁等等
>
> ## 意向锁
>
> ---
>
> intention，用于节约“判断是否可对该节点加锁时对子节点遍历的时间”，相当于一个flag
>
> - IS锁，表示他的子节点有S锁
> - IX锁，表示他的子节点有X锁
> - SIX锁，S+IX 读取整个，更新个别的

### 各类锁的相容性矩阵

#### 单粒度锁

| 相容性 | S    | X    |
| :----: | ---- | ---- |
|   S    | T    | F    |
|   X    | F    | F    |

#### 意向锁

| 相容性 | IS   | IX   |
| :----: | ---- | ---- |
|   IS   | T    | T    |
|   IX   | T    | T    |

#### 总表

| 相容性 | IS   | IX   | S    | SIX  | X    |
| ------ | ---- | ---- | ---- | ---- | ---- |
| IS     | T    | T    | T    | T    | F    |
| IX     | T    | T    | F    | F    | F    |
| S      | T    | F    | T    | F    | F    |
| SIX    | T    | F    | F    | F    | F    |
| X      | F    | F    | F    | F    | F    |

### 时间戳排序协议

> ![image-20230508154601074](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202305081546180.png)
> 
> ![image-20230508154538915](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202305081545078.png)
> 
> 优点：
>
> - 保证了可串行化；
> - 保证了无死锁：优先图中所有的弧都是从小时间戳到大时间戳，不存在环路；
>
> 缺点：
>
> - 不能保证可恢复性
> - 不能保证无级联回滚

### 快照隔离

> *MVCC* (MultiVersion Concurrency Control) 多版本并发控制
>
> 各事务在快照上进行操作，随后对各快照进行合并，解决冲突
>
> ![image-20230508155815703](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202305081558808.png)
>
> ![image-20230508155843183](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202305081558293.png)

## CH21 备份和恢复

### 数据备份

>  RAID 磁盘阵列

### 延迟修改技术

>  WAL【Write After Log】 预写日志系统
>
> LSM 【Log-Structured Merge-tree	日志结构合并树】先写内存，定期写外存

### 基于日志的恢复机制

> *undo redo 与 增加记录【一个事务必须要有开始和结束】
>
> 检查点	避免从零开始检查日志

### 远程备份系统

> 1. 故障检测	检测主站点是否发生故障
>
> 2. 控制权移交	主站点->备份站点->主站点
>
>    ps: 使用**热备份**【随时同步binlog等日志】可使备份站点瞬间实现接管
>
> 3. 恢复时间
> 4. 提交时间	日志记录到达备份站点后事务才宣称该事务已提交



## CH22 DBMS的体系结构

### 粗粒度并行 V.S. 细粒度并行

粗粒度并行：一个任务只被一个核处理，但任务之间并行

细粒度并行：一个任务可能被多个核处理

### *设计模式【面试题】

$$
设计模式
\begin{cases}
代理\\
装饰着\\
单例\\
MVC\\
...
\end{cases}
$$

> 单例模式：保证一个类只有一个实例
>
> 关键代码是将其构造函数私有化，设置一个实体为该类的静态对象
>
> 可使用lazy-load，需要用时再new实例【注意为获取实例设置为synchronized，使用双检锁】



### *三层模型	两级映射

三层：**外模式**【视图】-**概念模式**【结构】-**内模式**【数据】

两级映射：

- 第一级：保证逻辑独立性
- 第二级：保证物理独立性

![image-20230515145001251](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202305151450639.png)

### *并行系统性能参数

吞吐量：*QPS【每秒查询率】& *TPS【每秒事务处理率】

响应时间

### 并行系统的体系结构

![image-20230515150113719](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202305151501061.png)

### 分布式数据库

二阶段提交

> 二阶段提交的底层实现主要分成两个阶段：**请求阶段**、**提交阶段**
>
> **请求阶段：**
>
> - 协调者通知每个参与者准备提交；
> - 参与者在本地执行事务：
>
> 执行成功后，并不提交，告知协调者自己本地已经执行成功；
>
> 执行失败后，告知协调者本地作业执行故障
>
> **提交阶段：**
>
> - 协调者根据第一阶段收集到的参与者的返回信息，决定是否提交：
>
> 如果全部的参与者都反馈成功，那么协调者通知所有参与者提交事务
>
> 如果存在参与者反馈失败，则协调者通知所有参与者取消事务
>
> 收到全部参与者的成功commit信息后，完成本次提交

## CH23 特种数据库(基于对象的数据库)【不考且没用】

## CH24 特种数据库(XML基础知识)

### XML概念

> XML和HTML类似，都是一种文本标记语言；
>
> 与HTML不同的是：
>
> - HTML重在表示，XML重在数据交换；
> - HTML标签固定，XML的标记可扩展。
>
> 用于**数据传递**【JSON、XML等】
>
> ps: JSON传输效率更高，但XML扩展性更好

### *利用XPath访问XML文件信息【建议学习】

## CH25 云数据库【不怎么考】

$$
云计算组件
\begin{cases}
VM\\
worker
\end{cases}
\\
云存储组件
\begin{cases}
云盘&&非结构化\\
数据库&&结构化\\
HBase、Redis、Table、Kafka&&半结构化
\end{cases}
\\
云服务组件
\begin{cases}
BAE\\
GAE
\end{cases}
$$

### 三种云服务

![img](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202305171132961.webp)

云数据库与传统数据库(包括分布式数据库)的本质区别：云数据库的**计算与存储分离**

## CH26 NoSQL

Not-only SQL **非关系型**数据库 

特点：不需要预定义模型、弹性可扩展、分区、异步复制、**BASE**(基本可用、软状态/柔性事务、最终一致性)

### CAP定理【分布式系统中最多同时满足两者】

一致性(Consistency)：所有节点在同一时间具有相同的数据

可用性(Available)：保证每个请求不管成功或者失败都有响应

分隔容忍(Partiton tolerance)：系统中任意信息的丢失或失败不会影响系统的继续运作

CA【RDBMS】

**CP【MangoDB、HBase、Redis】【使用较多】**

AP【CouchDB、Cassandra、DynamoDB、Riak】

### NoSQL数据库的分类

1. 列存储【HBase、Cassandra、Hypertable】

   优点：减少投影时的数据IO；便于做数据压缩

2. 文档存储【MongoBD、FlockDB】

3. 键值存储【MemcacheDB、Redis】

4. 图存储【Neo4j、FlockDB】

5. 对象存储【db4o】

6. xml数据库

### 开源协议

![image-20230524104631993](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202305241046731.png)

## CH27 NewSQL

sql：支持强事务，且访问接口较为统一；但面对大数据性能受限，不支持高并发；一般在TB级以下

nosql：扩展性强；但不支持强事务，且访问接口不统一

NewSQL：介于两者之间，扩展性较强，且支持事务处理与sql通用接口
$$
NewSQL分类
\begin{cases}
1.从头开始，使用新架构&&Google Spanner\\
2.分布式中间件&&Shaeding Sphere\\
3.云数据库&&各大厂商的云数据库
\end{cases}
$$






---

---

# 问题专栏

> ## **总览：**
>
> - [3.1		mySQL除了主键外还可以使用什么进行索引？](#*一个问题（3/1实操演示）)
> - [3.6		B树和B+树之间的区别，b+树的优点？](#*面试问题（3/6）)
> - [3.6		模糊搜索（like）的底层逻辑，以及改进方法是？](#*3.6遗留问题)
> - [3.13	varchar char text之类的变量类型之间有何区别？（ps：越底层越好）](#*3.13遗留问题)
> - [3.15	聚簇索引与非聚簇索引？](#*3.15遗留问题)
> - [3.20	MySQL各种查询引擎的区别？](#*3.20遗留问题)
> - [3.20	简历](#*简历与面试)
> - [3.25	什么是OLTP，什么是OLAP？有没有其他方法解决这两者的不足？](#*3.25遗留问题)
> - [3.27	MySQL的ETL过程?](#*3.27遗留问题)
> - [3.29	数据分发架构](#*3.29遗留问题)
> - [4.3	在MySQL中，若字段(如text类型)大于4KB（块大小），则该如何存储？](#*4.3遗留问题)
> - [4.3	数据库与操作系统的堆和栈](#*面试问题(4/3))
> - [4.12	布隆过滤器](#*布隆过滤器(4/12))
> - [4.24	转博答辩PPT](#*转博答辩PPT(4/24))

## *一个问题（3/1实操演示）

> Q: mySQL除了主键外还可以使用什么进行索引？
>
> ---

> A: 主键索引、唯一索引、全文索引、普通索引、组合索引

## *面试问题（3/6）

> Q: B树和B+树之间的区别，b+树的优点？
>
> ---

> A: B+树不在非叶子节点存储数据，且叶子节点之间用指针串联，利于空间利用以及范围索引

## *3.6遗留问题

>  Q:模糊搜索（like）的底层逻辑，以及改进方法
>
>  如 where someone like "%you%"
>
>  ---

> A: 改进方法：
>
> 1. [索引条件下推ICP](https://blog.csdn.net/weixin_46058921/article/details/125346940)
>
> > 模糊搜索：不支持ICP之前，当进行索引查询时，首先根据索引来查找数据，然后再根据where条件来过滤，扫描了大量不必要的数据，增加了数据库IO操作。
> >
> > 索引条件下推ICP：在支持ICP后，MySQL在取出索引数据的同时，判断是否可以进行where条件过滤，将where的部分过滤操作放在存储引擎层提前过滤掉不必要的数据，减少了不必要数据被扫描带来的IO开销。
> >
> > 在某些查询下，可以减少Server层对存储引擎层数据的读取，从而提供数据库的整体性能。
>
> 2. [全文索引](https://blog.csdn.net/dreamyuzhou/article/details/120432893)
>
> > 全文索引采用了**反向索引(Inverted index)（倒排索引）**设计。反向索引存储单词列表，对于每个单词，存储该单词出现的文档列表。为了支持邻近搜索，每个单词的位置信息也以字节偏移量的形式存储。
> > 		反向索引:根据关键词反向得到该关键词的其它所有信息,比如该关键词所在的文件,在文件里出现的次数和行数等,这些信息就是用户查找该关键词时所要用的信息。![](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202303081056140.webp)
> >
> > 它是一个inverted index（反向索引），创建fulltext index时会自动创建6个auxiliary index tables（**辅助索引表**)，同时支持索引并行创建，并行度可以通过参数innodb_ft_sort_pll_degree设置，对于大表可以适当增加该参数值。
>
> 3. **左前缀匹配**的专项改进：直接**添加索引**即可加速
>
>    
>
> 4. **右后缀匹配**的专项改进：使用**生成列**
>
> > 对于where条件后的like '%xxx'是无法利用索引扫描，可以利用MySQL 5.7的生成列模拟函数索引的方式解决，具体步骤如下：
> >
> > > 1. **利用内置reverse函数将like '%风云'反转为like '云风%'，基于此函数添加虚拟生成列。**
> > > 2. **在虚拟生成列上创建索引。**
> > > 3. **将SQL改写成通过生成列like reverse('%风云')去过滤，走生成列上的索引。**
> >
> > ![image-20230307233840776](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202303072339343.png)

## *3.13遗留问题

> Q: varchar char text之类的变量类型之间有何区别？（ps：越底层越好）

> A: 
>
> - char：定长字符串，最大长度为255字节，不足255字节的部分用空格补齐，数据库检索出char类型的数据表时会自动截取后面的空格，也就是说字符串后面的空格也被删除掉，使用时要注意！！char会造成空间浪费，但定长的好处就是存取速度更高效。
>
> - varchar：可变字符串，最大长度为65535字节，其实最多只能存储65532字节，会占用1-3个字节用于存储长度。可以有默认值，尾部有空格不会被截取；
>   例如：在varchar（10）字段类型中插入"abc" 时，实际存储大小也只有3个字节；
>
> - text：text和varchar基本相同。text会忽略指定的大小，这和varchar有所不同，text不能设置默认值，尾部有空格不会被截取，text的65535字节会全部用来存储数据，额外两个字节用来存储数据大小。
>
> - NCHAR、NVARCHAR、NTEXT:这三种从名字上看比前面三种多了个“N”,它表示存储的是Unicode数据类型的字符。我们知道字符中，英文字符只需要一个字节存储就足够了，但汉字众多，需要两个字节存储，英文与汉字同时存在时容易造成混乱，Unicode字符集就是为了解决字符集这种不兼容的问题而产生的，它所有的字符都用两个字节表示，即英文字符也是用两个字节表示。nchar、nvarchar的长度是在1到4000之间。和char、varchar比较起来，nchar、nvarchar则最多存储4000个字符，不论是英文还是汉字；而char、varchar最多能存储8000个英文，4000个汉字。可以看出使用nchar、nvarchar数据类型时不用担心输入的字符是英文还是汉字，较为方便，但在存储英文时数量上有些损失。
>
> - 正常情况下，我们使用varchar也可以存储中文字符，但是如果遇到操作系统是英文操作系统并且对中文字体的支持不全面时, 在SQL Server存储中文字符为varchar就会出现乱码。
>
> - 结论：
>
>   1、经常变化的字段用varchar；
>
>   2、知道固定长度的用char；
>
>   3、超过255字节的只能用varchar或者text；
>
>   4、能用varchar的地方不用text；

> chatGpt:
>
> 在数据库中，Char、Varchar和Text类型都用于存储字符数据。它们的区别在于存储方式和长度限制。
>
> - Char类型是一种固定长度的字符类型，存储时会将数据填充到指定长度，多余的空间会被填充空格。例如，如果一个Char(10)类型的字段存储"abc"，那么它会被存储为"abc "（注意末尾有6个空格）。由于它的长度是固定的，因此查询效率比较高。
> - Varchar类型是一种可变长度的字符类型，存储时只会将实际数据存储下来，没有用到的空间不会占用。例如，如果一个Varchar(10)类型的字段存储"abc"，那么它会被存储为"abc"。由于它的长度是可变的，因此查询效率比Char类型稍低，但是它可以节省空间。
> - Text类型是一种可变长度的字符类型，可以存储比Varchar更长的字符数据。由于它的长度不固定，因此查询效率比Varchar和Char类型都要低。外联存储。
>
> 原因分析：
>
> - 查询效率与存储方式有关。Char类型是一种固定长度的字符类型，每个字段都会占用相同的存储空间，因此查询时可以直接定位到数据的位置，查询效率比较高。Varchar和Text类型是可变长度的字符类型，数据存储不是固定的，因此查询时需要先定位到数据的位置，再读取数据，查询效率比Char类型稍低。
> - char和varchar类型通常比text类型查询速度更快。这是因为char和varchar类型的存储方式不需要额外的指针或链接来引用数据，而text类型存储的大文本数据需要指针或链接来引用存储的文本数据。当查询text类型的数据时，需要花费额外的时间去访问指针或链接，导致查询速度变慢。

## *3.15遗留问题

> Q: 聚簇索引与非聚簇索引？

> A:
>
> > # [ITPUB博客](http://blog.itpub.net/26736162/viewspace-2692249/)（采纳）
> >
> > ## **聚簇索引**（clustered index ）和**非聚簇索引**（non-clustered index ） 
> >
> > 从物理存储角度来分， 索引可以分为聚簇索引和非聚簇索引，**区别主要看叶子节点存了什么数据** 。
> >
> > - **在InnoDB 里，索引 B+Tree 的叶子节点存储了整行数据的是主键索引，也被称之为聚簇索引。**聚簇索引是对磁盘上实际数据重新组织以按指定的一个或多个列的值排序的算法。特点是存储数据的顺序和索引顺序一致。一般情况下主键会默认创建聚簇索引，且**一张表只允许存在一个聚簇索引** ， 因为数据一旦存储，顺序只能有一种。找到了索引就找到了需要的数据，那么这个索引就是聚簇索引，所以主键就是聚簇索引，修改聚簇索引其实就是修改主键。
> >
> > - **索引B+Tree 的叶子节点只存储了主键的值和索引列的是非主键索引，也被称之为非聚簇索引。一个表可以有多个非聚簇索引** 。非聚簇索引的存储和数据的存储是分离的，也就是说可能找到了索引但没找到数据，需要**根据索引上的值（主键）再次回表查询**，非聚簇索引也叫做辅助索引。
> >
> > 聚簇索引的叶子节点就是**数据节点**，而非聚簇索引的叶子节点仍然是**索引节点**，只不过有指向对应数据块的**指针**。
> >
> > 聚簇索引查询相对会更快一些，因为主键索引树的叶子节点直接就是我们要查询的整行数据了 ， 而非主键索引的**叶子节点是主键的值，查到主键的值以后，还需要再通过主键的值再进行一次查询**（这个过程叫做	**“回表”** ， 也就是查了2 个索引树）。
>
> > # [CSDN回答](https://blog.csdn.net/m0_51212267/article/details/124073029)
> >
> > ## 聚簇索引
> >
> > 聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。
> >
> > 聚簇索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据，也将聚集索引的叶子节点称为数据页。这个特性决定了索引组织表中数据也是索引的一部分，每张表只能拥有一个聚簇索引。
> >
> > 每个InnoDB表都有一个特殊的索引，称为聚簇索引，用于存储行数据。
> >
> > 如果创建了一个主键，InnoDB会将其用作聚簇索引(如果主键没有逻辑唯一且非空的列或列集，最好是设置成自动递增的)。
> > 如果没有为表创建主键，则MySQL会在所有键列都不为NULL的情况下找到第一个UNIQUE索引，InnoDB会将其用作聚集索引。
> > 		如果表没有PRIMARY KEY或合适的UNIQUE索引，则InnoDB在包含行ID值的合成列上内部生成一个名为GEN_CLUST_INDEX的隐藏的聚集索引(隐藏的是看不到的，也就是说不会出现在desc table中，行ID是一个6字节的字段，随着插入新行而单调增加)。
> > 		从这三种情况来看的话，就是说不管你有没有创建主键，mysql都会给你弄一个聚簇索引给安排上，你创建了就用你设置的主键为聚簇索引，没有创建就给你来个隐藏的。
> >
> > ### 优点
> >
> > - 数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快
> >
> > - 聚簇索引对于主键的排序查找和范围查找速度非常快
> >
> > ### 缺点
> >
> > - 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键
> > - 更新主键的代价很高，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为不可更新。
> > - 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。
> >
> > ## 假设有一张person表：
> >
> > 主键是id，然后有两个普通索引idx_age，idx_name(btree类型的索引)，使用的是innodb引擎。
> >
> > 我们知道id就是聚簇索引，idx_age，idx_name是非聚簇索引，现在有三条数据，存储方式如下：
> >
> > 聚簇索引：![](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202303192135255.png)
> >
> > ## 非聚簇索引（辅助索引）
> >
> > ![](https://img-blog.csdnimg.cn/d7f005c939194f8ab6e5ff9febc13b55.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-H6KGX55qE6ICB6byg,size_16,color_FFFFFF,t_70,g_se,x_16)
> >
> > 可以看到聚簇索引后面是直接跟着的数据，而非聚簇索引指向的是聚簇索引的key值。
> >
> > 因此非聚簇索引查询数据需要先查到聚簇索引的key，然后用这个key去查询真正的数据(这个过程称为回表)。
> >
> > 也就是说非聚簇索引是需要查询两次。
> >
> > ![](https://img-blog.csdnimg.cn/62c4bd7322434a9292d9ef7964e90691.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-H6KGX55qE6ICB6byg,size_20,color_FFFFFF,t_70,g_se,x_16)
> >
> > 在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找。辅助索引叶子节点存储的不再是行的物理位置，而是主键值。通过辅助索引首先找到的是主键值，再通过主键值找到数据行的数据页，再通过数据页中的Page Directory找到数据行。
> >
> > ## 总结
> >
> > - InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，聚簇索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据，也将聚集索引的叶子节点称为数据页。这个特性决定了索引组织表中数据也是索引的一部分；
> > - 一般建表会用一个自增主键做聚簇索引，没有的话MySQL会默认创建，但是这个主键如果更改代价较高，故建表时要考虑自增ID不能频繁update这点。
> >
> > - 我们日常工作中，根据实际情况自行添加的索引都是辅助索引，辅助索引就是一个为了需找主键索引的二级索引，现在找到主键索引再通过主键索引找数据；

## *3.20遗留问题

> Q: 
> $$
> MySQL存储引擎\begin{cases}
> InnoDB\\
> MyISAM\\
> ...
> \end{cases}
> $$
> MySQL中的这些引擎有何区别？

> A:
>
> ## 常见存储引擎
>
> > MySQL 有多个查询引擎可供选择，每个引擎都有其独特的优缺点，适用于不同的使用场景。以下是一些常见的 MySQL 查询引擎：
> >
> > 1. InnoDB: InnoDB 是 MySQL 默认的存储引擎，它支持事务处理，提供行级锁定、外键约束等高级功能，适用于高并发和数据一致性要求较高的场景。因此，在大多数 OLTP 场景下，InnoDB 是首选的存储引擎。
> >
> >    > 有关OLTP：		
> >    >
> >    > ​		OLTP 是指联机事务处理（Online Transaction Processing），是一种用于处理和管理事务的计算机应用程序。在 OLTP 系统中，用户可以实时地提交事务，并且需要快速地获得响应和反馈。这种系统通常被用于处理许多用户交易的应用程序，如银行、电子商务和航空公司预订系统等。
> >    >
> >    > ​		OLTP 系统的特点是快速、高效、准确和可靠的处理大量小型交易，每个交易只涉及一小部分数据，并需要短时间内完成。这种系统通常使用关系数据库管理系统（RDBMS）来维护数据，并使用事务处理来保证数据的一致性和可靠性。因此，OLTP 系统需要具备高并发性、高可用性和高性能等特点。
> >    >
> >    > ​		与 OLTP 相对的是 OLAP（联机分析处理），用于对大量数据进行复杂的查询和分析。OLAP 系统通常需要处理大量的历史数据和统计数据，每个查询可能涉及数百万或数十亿行数据，并需要在较长的时间内计算结果。
> >
> > 2. MyISAM: MyISAM 是 MySQL 最古老的存储引擎，它不支持事务处理，但具有非常高的查询速度和简单的设计。MyISAM 适用于读取频繁、写入较少的应用程序，比如 Web 应用程序。
> >
> > 3. Memory: Memory 引擎是将数据存储在内存中的引擎，数据不会持久化到硬盘中。由于数据存储在内存中，因此它非常快，适用于需要快速读取数据的应用程序，但不适合用于存储大量数据。
> >
> > 4. NDB: NDB 是 MySQL Cluster 的存储引擎，它可在多台计算机上分布式运行，并支持事务处理、并发访问、自动故障恢复等功能。NDB 适用于需要高可用性和高性能的大型分布式应用程序。
> >
> > 这些存储引擎之间的区别在于它们的设计目标、特性和适用场景不同。根据应用程序的需求，选择最适合的存储引擎可以提高应用程序的性能和可靠性。
>
> ## 其他存储引擎
>
> > 除了 InnoDB 和 MyISAM，MySQL 还提供了一些其他的存储引擎，下面简单介绍一下它们的特点和应用场景。
> >
> > 1. Memory 引擎 Memory 存储引擎（也称为 Heap 存储引擎）将数据存储在内存中，因此读写速度非常快。它不支持事务、不支持外键，也不支持持久化存储，即重启 MySQL 后数据会丢失。但是，由于数据存储在内存中，因此它适用于需要快速读写数据的临时表或缓存表。
> > 2. CSV 引擎 CSV 存储引擎将数据以逗号分隔的形式存储在文本文件中。它不支持索引、不支持事务、也不支持外键，因此它适用于存储大量数据但不需要快速查询的场景，例如用于导入和导出数据的临时表。
> > 3. Archive 引擎 Archive 存储引擎以压缩的形式存储数据，可以大大减小磁盘空间的使用。它不支持索引、不支持更新和删除操作，只支持插入操作。因此，它适用于大量历史数据的存储，例如日志记录等场景。
> > 4. Blackhole 引擎 Blackhole 存储引擎将所有数据都丢弃，不存储任何数据。它适用于将写入操作转发到其他 MySQL 服务器的场景，例如用于主从复制时作为从服务器。
> > 5. NDB Cluster 存储引擎，它是一个分布式的、高可用的存储引擎，适用于大规模的、高并发的应用程序。
>
> ## InnoDB和MyISAM对比（ChatGPT）
>
> > InnoDB和MyISAM是MySQL数据库的两种常见存储引擎。它们在一些方面有相似之处，但在其他方面则有很大的不同。下面是它们之间的一些对比：
> >
> > 1. 事务支持：
> >
> > InnoDB支持事务，而MyISAM不支持。事务是指一组数据库操作，要么全部成功，要么全部失败。这对于需要数据完整性和一致性的应用程序非常重要。
> >
> > 2. 锁定机制&并发性能：
> >
> > InnoDB采用行锁定（row-level locking），而MyISAM采用表锁定（table-level locking）。这意味着在InnoDB中，只有受到操作影响的行会被锁定，而在MyISAM中，整个表会被锁定，这可能会影响并发性能。
> >
> > 3. 性能：
> >
> > 在一般情况下，MyISAM在读取方面的性能比InnoDB更好，因为它不需要管理复杂的事务机制和行级锁定。但是，InnoDB在写入和更新方面的性能通常比MyISAM更好，尤其是在高并发环境中。
> >
> > 4. 安全性：
> >
> > InnoDB支持ACID（原子性、一致性、隔离性和持久性）属性，而MyISAM不支持。这意味着在InnoDB中，如果出现异常情况，比如数据库断电，数据仍然会保持一致性和可恢复性。
> >
> > 5. 备份和恢复：
> >
> > 在备份和恢复方面，InnoDB比MyISAM更可靠.
> >
> > 6. 外键支持：
> >
> > 只有 InnoDB 支持外键，这意味着它可以在两个表之间建立引用完整性约束，保证数据的一致性和完整性。MyISAM 不支持外键，因此如果您需要使用外键约束，您需要选择 InnoDB。
> >
> > 7. 数据表大小限制
> >
> > MyISAM的数据表大小限制是65536 TB，而InnoDB的限制是实际上无限制的。
>
> ## [InnoDB和MyISAM区别（CSDN）](https://blog.csdn.net/qq_35642036/article/details/82820178)
>
> > 1. InnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务； 
> >
> > 2. InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败； 
> >
> > 3. InnoDB是聚集索引，使用B+Tree作为索引结构，数据文件是和（主键）索引绑在一起的（表数据文件本身就是按B+Tree组织的一个索引结构），必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。
> >
> >        MyISAM是非聚集索引，也是使用B+Tree作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
> >                                                                                                                                                                                                                                                 
> >        也就是说：InnoDB的B+树主键索引的叶子节点就是数据文件，辅助索引的叶子节点是主键的值；而MyISAM的B+树主键索引和辅助索引的叶子节点都是数据文件的地址指针。
> >
> > 4. InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快（注意不能加有任何WHERE条件）；
> >
> >    那么为什么InnoDB没有了这个变量呢？
> >    
> >        因为InnoDB的事务特性，在同一时刻表中的行数对于不同的事务而言是不一样的，因此count统计会计算对于当前事务而言可以统计到的行数，而不是将总行数储存起来方便快速查询。InnoDB会尝试遍历一个尽可能小的索引除非优化器提示使用别的索引。如果二级索引不存在，InnoDB还会尝试去遍历其他聚簇索引。
> >                                                                                                                                                                                                                                                                                                                                                                                                                                     
> >        如果索引并没有完全处于InnoDB维护的缓冲区（Buffer Pool）中，count操作会比较费时。可以建立一个记录总行数的表并让你的程序在INSERT/DELETE时更新对应的数据。和上面提到的问题一样，如果此时存在多个事务的话这种方案也不太好用。如果得到大致的行数值已经足够满足需求可以尝试
> >
> >
> > 5. Innodb不支持全文索引，而MyISAM支持全文索引，在涉及全文索引领域的查询效率上MyISAM速度更快高；PS：5.7以后的InnoDB支持全文索引了
> >
> > 6. MyISAM表格可以被压缩后进行查询操作
> >
> > 7. InnoDB支持表、行(默认)级锁，而MyISAM支持表级锁
> >
> >        InnoDB的行锁是实现在索引上的，而不是锁在物理行记录上。潜台词是，如果访问没有命中索引，也无法使用行锁，将要退化为表锁。
> >
> > 8. InnoDB表必须有唯一索引（如主键）（用户没有指定的话会自己找/生产一个隐藏列Row_id来充当默认主键），而Myisam可以没有
> >
> > 9. Innodb存储文件有frm、ibd，而Myisam是frm、MYD、MYI
> >
> >         Innodb：frm是表定义文件，ibd是数据文件
> >                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 
> >         Myisam：frm是表定义文件，myd是数据文件，myi是索引文件


## *简历与面试

> - 站在对方（HR）的角度思考问题
> - 非国企不需要写民族、政治面貌
> - 学历倒叙写
> - 绩点好看则 写
> - 与岗位无关的少写
> - 照片、自我评价可有可无
> - 不用表格（死板）
>
> > 面试三段论：
> >
> > 1. 脱稿两分钟自我介绍
> > 2. 列出的项目中觉得哪项最有意思？
> > 3. 算法面试
> >
> > PS：面试礼节 30分钟，开始闲聊需当心...

## *3.25遗留问题

>Q:什么是OLTP，什么是OLAP？有没有其他方法解决这两者的不足？

>A:
>
>>ChatGPT
>
>># OLTP&OLAP
>>OLTP（联机事务处理）和OLAP（联机分析处理）是数据管理领域中常用的两种处理方式，具有不同的特点和用途。
>>OLTP是指针对日常业务操作所需的数据处理，主要用于支持企业的**日常运营和交易处理**，例如订单处理、客户管理、库存管理等。OLTP处理的数据通常是实时数据，要求高并发、高可靠性和高效性，以确保业务能够快速地响应和处理。
>>OLAP则是指针对大规模数据分析和决策支持所需的数据处理，主要用于支持企业的**决策制定和战略规划**，例如销售分析、市场调研、预测分析等。OLAP处理的数据通常是历史数据，要求高度灵活、支持复杂的数据查询和聚合操作，以帮助企业洞察业务趋势和机会。
>>尽管OLTP和OLAP都是重要的数据处理方式，但它们也存在一些不足之处。例如，OLTP不适合处理大规模数据分析和复杂查询，而OLAP则可能无法及时响应实时业务需求。为了解决这些问题，还可以采用以下方法：
>>1. 数据仓库：数据仓库是专门用于存储和管理企业数据的系统，可以支持OLAP分析和查询。通过将数据从多个源整合到一个数据仓库中，可以帮助企业更好地管理和分析数据，支持决策制定。
>>2. 数据挖掘：数据挖掘是一种利用统计学、机器学习等技术从大规模数据中挖掘出有价值信息的过程。通过应用数据挖掘技术，可以帮助企业发现隐藏在数据中的规律和趋势，以支持决策制定。
>>3. 决策支持系统：决策支持系统是一种可以帮助企业进行决策制定的计算机应用系统。通过集成OLAP、数据挖掘、模型分析等技术，可以提供更好的决策支持和预测能力，以帮助企业更好地把握业务机会和应对挑战。
>
>># OLTP不足与改进
>>OLTP（Online Transaction Processing）是一种基于交易的数据处理方式，适用于需要快速处理大量事务的业务场景，如银行、零售、物流等。虽然OLTP有很多优点，但也存在一些不足之处。以下是OLTP的优点和不足以及如何解决的建议：
>
>>## 优点：
>>1.高并发性能：OLTP系统通常需要同时处理大量的交易，因此需要具备高并发性能，能够支持多用户同时进行数据操作。
>>2.数据一致性：由于OLTP系统的核心是处理事务，因此要求数据的一致性和完整性，确保数据的正确性和有效性。
>>3.实时处理：OLTP系统需要实时响应用户的请求，并且在很短的时间内完成数据处理，以便用户及时获得结果。
>>4.可扩展性：OLTP系统需要具备良好的可扩展性，以便在业务增长和系统升级时能够满足需求。
>
>>## 不足：
>>1.数据冗余：由于需要保证数据的一致性，OLTP系统通常会采用冗余数据的方式，导致数据冗余增加，对存储资源的利用效率不高。
>>2.性能瓶颈：由于OLTP系统需要处理大量的事务，如果设计不合理或者运维不当，就容易出现性能瓶颈，导致系统运行缓慢，甚至崩溃。
>>3.复杂性高：由于OLTP系统需要处理多种不同的业务场景，因此系统的设计和维护都比较复杂，需要投入大量的人力和物力资源。
>
>>## 如何解决：
>>1.数据冗余：可以采用数据归档、数据压缩等方式来减少数据冗余，提高存储资源的利用效率。
>>2.性能瓶颈：可以通过采用合理的系统架构、调整系统参数、使用高效的数据库等方式来解决性能瓶颈问题。
>>3.复杂性高：可以采用模块化的设计方式、自动化运维等方式来减少系统的复杂性，提高系统的可维护性和稳定性。此外，可以使用现有的开源框架和工具，如Spring、MyBatis等，来简化系统的开发和维护。
>
>># OLAP不足与改进
>>OLAP（联机分析处理）是一种数据处理技术，用于分析多维数据集。它具有以下优点：
>
>>## 优点：
>>1. 多维视角：OLAP 可以通过多个维度（如时间、地理位置、产品类别等）来组织和分析数据，从而提供更深入的分析视角。
>>2. 快速响应：OLAP 对大数据集的查询和汇总操作具有快速响应能力，可以快速提供准确的结果。
>>3. 数据准确性：OLAP 可以确保数据的准确性和一致性，因为它通常使用事实表和维度表的结构来组织数据。
>
>>## 缺点：
>>1. 处理大数据集的能力受限：OLAP 对于非常大的数据集可能会受到处理能力的限制，导致查询响应时间变慢。
>>2. 系统复杂性：由于 OLAP 通常需要大量的数据仓库和 ETL（抽取、转换和加载）流程，因此它的实现和维护可能比较复杂。
>>3. 需要高度设计：OLAP 的性能取决于其数据模型的设计质量，需要进行高度设计，从而需要专业人士的参与。
>>要解决这些问题，可以采用以下方法：
>
>>## 解决方法：
>>1. 增加硬件资源：可以增加服务器的内存、处理器和存储容量等硬件资源，以提高 OLAP 的处理能力。
>>2. 数据分区和压缩：可以使用数据分区和压缩等技术来减少查询的数据量，从而提高查询性能。
>>3. 优化数据模型：可以优化数据模型的设计，使用合适的维度、事实和聚合等数据结构，从而提高查询性能和准确性。
>>4. 自动化 ETL 流程：可以使用自动化工具来减少 ETL 流程的复杂性，从而降低 OLAP 的实现和维护成本。
>>5. 分布式 OLAP：可以采用分布式 OLAP 技术，将数据和查询操作分布在多个节点上，从而提高 OLAP 的处理能力和可伸缩性。
>
># 课上讲解
>
>![image-20230327145629746](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202303271456336.png)
>
>OLTP行式存储，OLAP列式存储（便于总体分析与数据压缩（同种数据类型压缩效率更高））
>
>> 如int型Δ压缩，存储数据间的插值，相较通用压缩效率高；浮点压缩有VLDB中lry的顶会论文等

## *3.27遗留问题

> Q：MySQL的ETL过程？包括从何处取数据？

> A:
>
> > # [知乎](https://zhuanlan.zhihu.com/p/352337320)
> >
> > ## **提取 extract**
> >
> > 在提取阶段，解决的是**数据来源问题**。主要有以下几种：
> >
> > - 业务数据
> >   在我们企业运行过程中，会有一些用户的交易数据，如用户的购买订单、退款退货、用户发布的视频、用户的注册信息等等，这些都存在我们的业务数据库里，这些数据库通常是关系型数据库，这是我们获取数据的一个重要来源。
> > - 文件数据
> >   还有一些数据是有文件的形式存在，比如我们服务器运行的 log，它记录了用户对网站的请求情况，再比如我们通过埋点收集的日志文件，记录了用户的交互。
> > - 第三方数据
> >   通过第三方购买或者合作形式信用的数据，这些数据可以作为我们业务分析的补充数据。这些数据一般通过和第三方机构的接口（API）形式，对接传输过来。三方的来源、数据形式格式可能有多种多样，就需要我们分别进行对接处理。
> >
> > 数据的格式和形式一般有以下几种：
> >
> > - 关系型数据库 SQL，RDBMS
> > - 文件型数据库 NoSQL
> > - 日志文件
> > - XML/Html
> > - JSON
> > - CSV/TSV（flat files）
> > - 等等
> >
> > Staging Area 为缓存区，在数据加载后进行处理时，将过程中的结果暂时存放起来，有些计算需要一定的硬件资源和时间，设定缓冲区可以对 ETL 有很大有帮助。
> >
> > **提取是把多种多样的原格式数据抽象出来，形成统一的数据格式先放入==缓存区==，不会直接进入数据仓库，等待下一步转换操作**。
> >
> > ## **转换 transform**
> >
> > 弄清楚了数据来源，前边做了数据的整合，对文件格式进行了一些处理。本步骤，根据我们的商业需要，我们用一些规则、方法进行**数据处理**。一般常见的转换操作有：
> >
> > - 筛选：筛选部分数据，或者部分字段，提取一部分有用的数据
> > - 清理：缺失值填充、默认值设定、枚举映射等，如将一些编码转为可识别的符号，比如省份代码 sh 转为「上海」
> > - 合并：将多个属性合并在一起
> > - 格式转换：，如原数据是一下个时间戳（timestamp），我们为了方便后续分析转换为时间格式，指定时区
> > - 拆分：将单个属性值拆分为多个属性值，如原为一个邮编，拆分解析成省份、城市等多个字段
> > - 排序：按期望的数据顺序进行排列
> > - 计算：如原数据为年龄，用当前年份减去年龄同，取得出生年份
> >
> > 原则：
> >
> > - 建数据仓库时尽量保留原始数据，支持多样需求
> > - 为特定报表时尽量取所需要的数据
> >
> > ## **加载 load**
> >
> > 数据的加载方式一般有以下两种重要类型：
> >
> > - 全量加载（Full load / Bulk load）
> > - 增量加载（Incremental load / Refresh load）
> >
> > 全量一般是第一次进行数据加载，这个过程比较长，也有种情况是业务数据存在历史全量数据不停更新的情况，这种情况无论何时都需要全量加载。还有一种情况会追溯一定的时间周期内的数据进行加载，如此业务30天之前的数据不会有再任何变化。
> >
> > 增加加载最为常见，一般一日加载一次，加载上一日数据，也有一周或者一月加载一次的。
> >
> > 加载数据是数据进入数据仓库的最后一步，加载是依赖提取和转换的，因此，加载数据是一个完整的 ETL 过程，这个过程需要大量的数据流转加工时间，而且是周期性重复的工作，所以一般由系统自动完成，执行时间为业务一个最小周期——日（实时数仓会选择更小的时间粒度，如10分钟一次），同时选择业务量小的凌晨进行。
> >
> > 除了增加新增加数据，加载同时伴随着对已加载数据的修改。选择何种加载类型，以及加载周期、加载内容，要看具体业务，产品经理和分析师分析需求最终确定一个最优的方案。
>
> > # ChatGPT
> >
> > 在MySQL中进行ETL操作，通常有以下步骤：
> >
> > 1. 提取（Extract）数据：从数据源中提取数据，可以使用MySQL自带的工具或第三方ETL工具。例如，使用MySQL的SELECT语句从关系型数据库中提取数据，使用LOAD DATA INFILE语句从文件中提取数据，使用REST API或Web爬虫从Web API中提取数据。
> >
> >    ps:ETL工具（例如Talend、Pentaho或Apache Nifi）可以直接连接到MySQL数据库，并使用图形界面来创建数据提取任务。在任务中，可以指定要提取的数据表、字段和过滤条件，并将提取的数据直接写入到目标数据存储中（例如Hadoop集群或数据仓库）。
> >
> > 2. 转换（Transform）数据：将提取的数据进行转换处理，包括清洗、过滤、合并、拆分、归一化等。清洗数据可使用MySQL内置函数，例如TRIM()、REPLACE()、SUBSTRING()等，过滤数据可使用WHERE语句和正则表达式等，合并和拆分数据可使用JOIN和UNION语句，归一化数据可使用约束和外键等。
> >
> > 3. 加载（Load）数据：将转换后的数据加载到MySQL中，可以使用INSERT、UPDATE和DELETE语句，使用LOAD DATA INFILE语句和数据导入工具等。在加载数据之前，需要创建数据库和表结构，确保转换后的数据符合MySQL的数据类型和约束。
> >
> > 在进行ETL操作时，需要注意以下几点：
> >
> > 1. 数据提取和加载的效率：尽量使用高效的数据提取和加载方式，例如批量加载数据、使用索引和分区等。
> > 2. 数据转换的准确性：转换过程中需要保证数据的准确性和完整性，避免数据丢失和错误。
> > 3. 数据加载的安全性：加载数据时需要注意数据的安全性，防止SQL注入攻击和数据泄露。
> > 4. 数据质量的验证：在数据ETL过程结束后，需要验证已加载的数据的质量和准确性，避免数据质量问题对后续业务产生负面影响。
>
> > # 课上讲解
> >
> > *准备多个数据库，一个性能较强的主数据库用于处理写操作，其余的从数据库用于处理读操作；主从数据库之间使用binlog保持同步（binlog是一个二进制日志文件）

## *3.29遗留问题

> Q: 1000TB数据，拷贝1000台设备中，每台设备的带宽为100MB/s，最少同步时间是？

> A:
>
> ![image-20230402224505164](https://cdn.jsdelivr.net/gh/XXL2002/PicGo@main/202304022245539.png)
>
> ## 课上讲解
>
> 直接串联，50上行，50下行

## *4.3遗留问题

> Q: 在MySQL中，若字段(如text类型)大于4KB（块大小），则该如何存储？

> A:
>
> > [mysql底层数据存储原理_mysql 数据库存储的原理_会飞的IT蜗牛的博客-CSDN博客](https://blog.csdn.net/ymb615ymb/article/details/128723576)
>
> > [MySQL中text类型的详细介绍（从存储结构到使用方法全掌握） - 老白网络 (yzktw.com.cn)](https://www.yzktw.com.cn/post/589974.html)
> >
> > 一、text类型的存储结构
> >
> > text类型的存储结构是基于BLOB的，BLOB是一种二进制大型对象，它可以存储任意长度的二进制数据。在MySQL中，text类型的存储结构由两部分组成：指针和数据。
> >
> > 
> >
> > 指针：text类型的指针用于指向数据存储的位置，它的长度为4个字节，即32位。因此，text类型可以存储的最大数据长度为4GB。
> >
> > 
> >
> > 数据：text类型的数据是存储在磁盘上的，它的长度可以任意。当我们向text类型的字段中插入数据时，MySQL会将数据写入磁盘，并将指针指向数据存储的位置。
> >
> > 二、text类型的使用技巧
> >
> > \1. text类型的数据长度限制
> >
> > 虽然text类型可以存储任意长度的数据，但是在实际使用中，我们需要注意其长度限制。由于text类型的数据是存储在磁盘上的，因此在查询时需要从磁盘中读取数据，这会影响查询的效率。为了提高查询效率，我们应该尽量避免存储过长的数据。
> >
> > \2. text类型的索引
> >
> > 由于text类型的数据是存储在磁盘上的，因此不能直接使用索引进行查询。但是，我们可以使用全文索引来优化text类型的查询效率。全文索引是一种特殊的索引类型，它可以对text类型的数据进行分词，从而提高查询效率。
> >
> > \3. text类型的备份与恢复
> >
> > 由于text类型的数据是存储在磁盘上的，因此在备份和恢复时需要注意一些细节。在备份时，我们需要备份整个数据库，包括数据和表结构。在恢复时，我们需要先创建表结构，然后再将数据导入表中。
> >
> > \4. text类型的数据存储格式aryary格式存储数据，那么数据将以二进制形式存储，这可以提高查询效率。如果使用text格式存储数据，那么数据将以文本形式存储，这可以提高可读性。
> >
> > \5. text类型的数据操作
> >
> > 在使用text类型的数据时，我们可以使用一些特殊的函数来进行操作，例如：SUBSTR、LENGTH、CONCAT等。这些函数可以帮助我们快速地截取、计算、拼接text类型的数据。
>
> > ## ChatGPT
> >
> > MySQL底层存储方法是基于磁盘的关系型数据库存储模型。在磁盘上，MySQL将数据存储为一个或多个数据文件，其中每个文件代表一个数据库表或索引。当执行查询时，MySQL会从这些文件中读取数据并将其加载到内存中进行处理。
> >
> > 在存储TEXT类型数据时，MySQL会将其分配到一个单独的数据页中，并将指向该页的指针存储在表中。MySQL使用了类似于B-tree的数据结构来管理这些数据页，以便快速定位到需要访问的数据页。
> >
> > 当数据页被填满时，MySQL会分配一个新的数据页来存储剩余的数据。如果需要删除或更新数据，则MySQL会将其标记为已删除或已更新，并在后台定期进行数据清理和压缩操作，以优化磁盘空间的利用率。
> >
> > 对于较大的TEXT类型数据，MySQL还支持行级别存储和压缩，以节省存储空间并提高查询性能。在行级别存储模式下，MySQL将文本数据存储在独立的数据页中，并使用指针来引用它们。在行级别压缩模式下，MySQL使用一种称为LZ77的算法对文本数据进行压缩，并将压缩后的数据存储在数据页中。
> >
> > 总的来说，MySQL底层存储方法是非常高效和可靠的，它能够有效地管理和优化大量数据的存储和访问，以支持高效的数据处理和查询操作。
> >
> > ## 行级别存储
> >
> > MySQL中的行级别存储是指，数据库管理系统（DBMS）存储数据时以行为单位，而不是以表为单位。每一行都可以独立进行读写操作，也可以独立地被锁定或解锁。这种存储方式使得MySQL能够实现更加细粒度的控制和更高的并发性能。
> >
> > 在行级别存储中，每个表中的每一行都有一个唯一的行标识符（ROWID），可以用来查找和访问该行的数据。当需要访问某一行的数据时，DBMS会使用该行的ROWID来定位该行，并读取或修改该行的数据。
> >
> > 相比之下，传统的表级别存储方式是以表为单位进行读写操作，因此在进行并发操作时可能会出现锁竞争，从而导致性能下降。因此，在高并发场景下，行级别存储往往能够提供更好的性能和可伸缩性。
> >
> > ## MySQL中单个数据页不足以存储数据怎么办
> >
> > 如果MySQL中单个数据页不足以存储数据，MySQL会将数据分成多个页存储。这种情况下，MySQL采用的存储引擎会负责数据的分页管理和维护，确保数据的完整性和一致性。
> >
> > 通常情况下，当一个数据页已经存储满了之后，MySQL会将新的数据存储到另外一个页中。如果新的数据行比较小，可能会和其他小的数据行一起存储在同一个页中，而如果新的数据行比较大，MySQL可能会为其分配一个新的数据页来存储。
> >
> > MySQL的存储引擎还会维护一个数据页的链表，用来跟踪所有数据页的使用情况。当一个页已经不再使用时，MySQL会将其从链表中移除，并将其空间释放出来供其他数据使用。
> >
> > 如果需要优化MySQL的数据存储，可以考虑使用更高效的存储引擎，如InnoDB，该存储引擎支持更高级别的数据压缩和索引技术，可以更好地管理和优化数据存储。

## *面试问题(4/3+4/12)

> 数据库与操作系统的堆和栈
>
> 手写代码时注意参数合法性检验

## *布隆过滤器(4/12)

> 利用多个哈希判断数据是否属于一个很大的数据集合中
>
> 如判断是否是垃圾邮件等
>
> **介绍布隆过滤器**
>
> > ## ChatGPT
> >
> > 布隆过滤器（Bloom Filter）是一种快速、高效的数据结构，用于判断一个元素是否属于一个集合。它可以在非常快的时间内进行查询，并且使用的空间很小。
> >
> > 它的基本思想是**使用多个哈希函数对元素进行哈希**，将哈希值映射到一个**位数组**中。当一个元素被加入集合时，将其哈希值对应的位数组中的对应位置设为1。当需要查询一个元素是否属于集合时，对该元素进行哈希，检查其对应的位数组位置是否都为1，若存在一个位置不为1，则可以确定该元素不在集合中。
> >
> > 布隆过滤器有两个参数：**哈希函数的个数**和**位数组的大小**。哈希函数的个数越多，误判的概率越小，但需要更多的时间和空间来计算和存储哈希值。位数组的大小越大，误判的概率越小，但需要更多的空间来存储位数组。
> >
> > 布隆过滤器的一个重要应用是在大规模数据处理中的数据去重，它可以快速地检查某个元素是否出现过，从而避免重复处理。

## 转博答辩PPT(4/24)

> 

# 查询优化实战分享(4/17学长)

## ANTLR(ANother Tool For Language Recognization)

http://lab.antlr.org/

提供语法即可完成词法、语法分析，并构建分析树

## 有关project2

1. 使用ANTLR
2. 使用START-DB（GitHub开源 ）

# Project2

ANTLR

参考try #188

# 学术汇报

### 数据分片中间件

将请求路由至不同数据库，再将结果合并后返回；基于现有的关系型数据库，较为稳妥

### *数据切分

横向切分：表的数据结构不变，将原表切分为多个新表，分摊记录条数

纵向切分：改变表的结构，将原表切分为多个新表，分摊表的属性
